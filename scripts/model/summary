#!/usr/bin/env python

"""
This script takes a trained model and labels and computes classification perfomance
statistics.
"""

from __future__ import print_function

import sys
import os
import argparse
import gzip
#import cPickle as pickle
import pickle
import itertools
import pandas as pd
import numpy as np
import six
import random

root_split = os.path.dirname(os.path.abspath(__file__)).split('/')[:-2]
sys.path.append('/'.join(root_split))
sys.path.append('/'.join(root_split+['rnn']))

import src.data as data
import src.parser as parse
import src.loader as loader
from src.progress import Progress
import src.model
import src.utils as utils

def argument_parser():
    parser = argparse.ArgumentParser(description='This script takes a trained model and labels and computes classification perfomance statistics.')
    parser.add_argument('-m', '--model', metavar='FILE', help='model file')
    parser.add_argument('-y', '--labels', metavar='FILE', help='labeled regions file')
    parser.add_argument('-f', '--fixed', metavar='FILE', help='File containing fixed length features')
    parser.add_argument('-t', '--tracks', metavar='FILE', nargs='*', help='Full feature track files')
    parser.add_argument('--downsample', action='store_true', help='sample regions for calculating stats')
    parser.add_argument('-o', '--output', metavar='FILE', default=None, help='Destination file (default: stdout)')
    return parser

def find_file(paths, cell_line):
    for path in paths:
        if cell_line in path:
            return path

def find_files(paths, cell_line):
    return [path for path in paths if cell_line in path]

def read_gene_expression(path):
    with open(path) as f:
        for x in parse.read_gene_expression(f):
            yield x

def load_gene_expression_cell_lines(paths, cell_lines):
    for cell_line in cell_lines:
        print('# Loading', cell_line, 'gene expression', file=sys.stderr)
        expr = [read_gene_expression(path) for path in find_files(paths, cell_line)]
        expr = data.combine_gene_expression(itertools.chain(*expr))
        yield cell_line, six.iteritems(expr)

def get_regions(labels_df):
    regions = []
    for row in labels_df.itertuples():
        regions.append(tuple(row[1:]))
    return regions

def open_fixed(fixed):
    print('# Opening fixed features:', fixed, file=sys.stderr)
    F = pd.read_csv(fixed, sep='\t', index_col=0)
    F = F.astype(np.float32)
    return F

def open_features(regions, tracks, fixed, **kwargs):
    from src.prefetcher import Prefetcher
    it = loader.RegionsIterator(tracks, fixed, regions, **kwargs)    
    #return it
    return Prefetcher(it, 2048, thread=False)

def open_validation_features(regions, tracks, fixed):
    cell_lines = set(next(zip(*regions)))
    tracks = {cell_line: find_file(tracks, cell_line) for cell_line in cell_lines}
    print('# Using validation tracks:', list(tracks.values()), file=sys.stderr)
    return open_features(regions, tracks, fixed)

def calc_stats(model, data):
    y_true = []
    y_pred = []
    progress = Progress(out=sys.stderr)
    pbar = progress.progress_monitor()
    pbar(0, 'Predict')
    n = len(data)
    prog = 0
    for b, [X, X_M, F, Y, Y_M] in utils.chunks(data, 512):
        Y = Y[...,0]
        Y_M = Y_M[...,0]
        P = model.predict_proba(X, X_M, F)
        y_true.extend(Y[Y_M==1].flatten().tolist())
        y_pred.extend(P[Y_M==1].flatten().tolist())
        prog += b
        pbar(prog/n, 'Predict')

    from sklearn.metrics import average_precision_score, roc_auc_score
    df = pd.DataFrame()
    df['auPRC'] = average_precision_score(y_true, y_pred)
    df['auROC'] = roc_auc_score(y_true, y_pred)
    return df

def sample_stats(model, data):
    data.randomize = True
    data.infinite = True

    sample_size = 4096*2
    num_samples = 10

    y_true = []
    y_pred = []
    progress = Progress(out=sys.stderr)
    pbar = progress.progress_monitor()
    pbar(0, 'Predict')
    n = sample_size*num_samples
    prog = 0
    for _ in range(sample_size):
        yt, yp = [], []
        for b, [X, X_M, F, Y, Y_M] in utils.chunks(data, 512):
            Y = Y[...,0]
            Y_M = Y_M[...,0]
            P = model.predict_proba(X, X_M, F)
            yt.append(Y[Y_M==1].flatten())
            yp.append(P[Y_M==1].flatten())
            prog += b
            pbar(prog/n, 'Predict')
            if prog >= n:
                break
        yt = np.concatenate(yt)
        yp = np.concatenate(yp)
        y_true.append(yt)
        y_pred.append(yp)

    from sklearn.metrics import average_precision_score, roc_auc_score
    auprc = [average_precision_score(yt, yp) for yt,yp in zip(y_true, y_pred)]
    auroc = [roc_auc_score(yt, yp) for yt,yp in zip(y_true, y_pred)]
    df = pd.DataFrame()
    df['Stat'] = ['Median', 'Stdev']
    df['auPRC'] = [np.median(auprc), np.sqrt(np.var(auprc))]
    df['auROC'] = [np.median(auroc), np.sqrt(np.var(auroc))]
    return df

def main():
    args = argument_parser().parse_args()

    #load the model
    print('# Loading model:', args.model, file=sys.stderr)
    model = src.model.load(args.model)
    sys.stderr.flush()

    #load the regions
    print('# Loading data', file=sys.stderr)
    with gzip.open(args.labels) as f:
        labels_df = pickle.load(f)
    print('# Number of regions:', len(labels_df), file=sys.stderr)
    sys.stderr.flush()
    cell_lines = set(labels_df['Cell Line'])
    regions = get_regions(labels_df)

    #make the data loader
    fixed = open_fixed(args.fixed)
    data = open_validation_features(regions, args.tracks, fixed)

    if args.downsample:
        df = sample_stats(model, data)
    else:
        df = calc_stats(model, data)


    out = sys.stdout if args.output is None else open(args.output, 'w')
    df.to_csv(out, sep='\t', float_format='%.5f', header=True, index=False)


main()









